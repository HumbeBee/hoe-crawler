This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-11-09T05:21:07.444Z

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

Additional Info:
----------------

For more information about Repomix, visit: https://github.com/yamadashy/repomix

================================================================
Repository Structure
================================================================
cmd/
  config/
    config.go
  list/
    main.go
gaito/
  scraper_detail.go
  scraper_list.go
  scraper_report.go
internal/
  models/
    hoe.go
    reporter.go
  sites/
    gaito/
      detail.go
      list.go
      report.go
      scraper.go
      selectors.go
  utils/
    browser/
      element.go
      rate_limit.go
      retry.go
    errutil/
      handler.go
      level.go
    common.go
utils/
  common.go
  element.go
  rate_limit.go
  retry.go
.gitignore
go.mod
go.sum
main.go

================================================================
Repository Files
================================================================

================
File: cmd/config/config.go
================
package config

import "log"

const (
	BaseUrl          = "https://www.gaito.love"
	RequestPerSecond = 1.0
)

// InitLogger configures the standard logger with:
// - Date and time (2006/01/02 15:04:05)
// - File name and line number (file.go:123)
// This helps with debugging by showing exactly where and when each log occurred
func InitLogger() {
	log.SetFlags(log.LstdFlags | log.Lshortfile)
}

================
File: cmd/list/main.go
================
package main

import (
	"log"

	"github.com/haovoanh28/gai-webscraper/cmd/config"
	"github.com/haovoanh28/gai-webscraper/internal/sites/gaito"
)

func main() {
	config.InitLogger()

	log.Println("Starting URL list scraper ...")

	scraper := gaito.NewScraper(config.BaseUrl, config.RequestPerSecond)

	urls := scraper.GetList()
}

================
File: gaito/scraper_detail.go
================
package gaito

import (
	"fmt"
	"strings"
	"time"

	"github.com/haovoanh28/gai-webscraper/internal/models/hoe"
	"github.com/haovoanh28/gai-webscraper/utils"

	"github.com/go-rod/rod"
)

func ProcessDetailUrl(url string) *hoe.Hoe {
	defer func() {
		if err := recover(); err != nil {
			fmt.Printf("Error processing detail URL %s: %v\n", url, err)
		}
	}()

	result := ProcessDetailPage(url)
	return &result
}

func ProcessDetailPage(detailUrl string) hoe.Hoe {
	url := BaseUrl + detailUrl

	id := utils.GetIDFromUrl(detailUrl)

	// Wait until content element is visible
	page := rod.New().MustConnect().MustPage(url)
	containerElement := page.MustElement(`.container.seduction-container .ow_page_container`).MustWaitVisible()
	detailInfoElement := page.MustElement(`.tab-content`).MustWaitVisible()

	var mainInfo hoe.HoeMainInfo
	mainInfo.Name = utils.GetElementsText(containerElement, `body > div.container.seduction-container > div.knn_page_wrap > div.ow_page_padding > div > div > div > div > div > div:nth-child(3) > div > h1`, "name")
	mainInfo.ImageUrl = utils.GetElementAttribute(containerElement, `body > div.container.seduction-container > div.knn_page_wrap > div.ow_page_padding > div > div > div > div > div > div:nth-child(3) > div > div:nth-child(3) > div > div > div > div.tab-pane.ng-scope.active > div.jumbotron.ng-scope > div > div.col-md-3.col-sm-4.media.escort_item_wrap > div > image-placeholder > img`, "src", "image_url")
	// Ex: "300 k" => "300k"
	price := utils.GetElementText(detailInfoElement, `.jumbotron .fa.fa-money + span`, "price")
	mainInfo.Price = strings.ReplaceAll(price, "\u00A0", "")
	// Ex: "0123.456.789" -> "0123456789"
	phone := utils.GetElementText(detailInfoElement, `.jumbotron .fa.fa-phone + a`, "phone")
	mainInfo.Phone = strings.ReplaceAll(phone, ".", "")
	mainInfo.Address = utils.GetElementText(detailInfoElement, `.jumbotron .fa.fa-map-marker + a`, "address")
	mainInfo.Author = utils.GetElementText(detailInfoElement, `.jumbotron .fa.fa-user + a`, "author")
	mainInfo.Status = utils.GetElementText(detailInfoElement, `.jumbotron .fa.fa-file-o + span`, "status")

	var detailInfo hoe.HoeDetailInfo
	detailInfoElement = page.MustElement(`product-attribute .table-responsive`).MustWaitVisible()
	time.Sleep(2 * time.Second)
	detailInfo.BirthYear = utils.GetElementText(detailInfoElement, `body > div.container.seduction-container > div.knn_page_wrap > div.ow_page_padding > div > div > div > div > div > div:nth-child(3) > div > div:nth-child(3) > div > div > div > div.tab-pane.ng-scope.active > div:nth-child(2) > product-attribute > div > div > div > table > tbody > tr:nth-child(3) > td:nth-child(2) > attribute-dob-box > div > div`, "birth_year")
	detailInfo.Height = utils.GetElementText(detailInfoElement, `product-attribute table > tbody > tr:nth-child(4) > td:nth-child(2) > attribute-number-box .ng-scope`, "height") + "cm"
	detailInfo.Weight = utils.GetElementText(detailInfoElement, `product-attribute table > tbody > tr:nth-child(5) > td:nth-child(2) > attribute-number-box .ng-scope`, "weight") + "kg"
	detailInfo.From = utils.GetElementsText(detailInfoElement, `product-attribute table > tbody > tr:nth-child(9) > td:nth-child(2) > attribute-radio-box span span[ng-repeat="item in attributeDto.settings.values"]`, "from")
	detailInfo.Service = utils.GetElementsText(detailInfoElement, `product-attribute table > tbody > tr:nth-child(12) > td:nth-child(2) > attribute-choices-box span span[ng-repeat="item in attributeDto.settings.values"]`, "service")
	detailInfo.Duration = utils.GetElementText(detailInfoElement, `product-attribute table > tbody > tr:nth-child(15) > td:nth-child(2) > attribute-text-box span`, "duration")
	detailInfo.WorkTime = utils.GetElementText(detailInfoElement, `product-attribute table > tbody > tr:nth-child(16) > td:nth-child(2) > attribute-text-box span`, "work_time")

	// Get report urls
	var reportUrls []string
	page.MustElement(`li[index="2"] a.nav-link`).MustClick().MustWaitLoad()
	time.Sleep(1 * time.Second)
	reportTabElement := page.MustElement(`product-review[ng-if="reviewTabLoaded"]`)

	for {
		reportElements, err := reportTabElement.Elements(`div[ng-repeat="review in reviews"]`)
		if err != nil {
			panic(err)
		}
		if len(reportElements) == 0 && len(reportUrls) == 0 {
			continue
			// panic(fmt.Errorf("empty reportElements ?: %v", err))
		}

		for _, reportElement := range reportElements {
			btnElement, err := reportElement.Element(`a.view_more_report`)
			if err != nil {
				panic(fmt.Errorf("failed to get view_more_report: %v", err))
			}

			reportUrl, err := btnElement.Attribute("href")
			if err != nil {
				panic(fmt.Errorf("failed to get reportUrl: %v", err))
			}
			reportUrls = append(reportUrls, *reportUrl)
		}

		if len(reportUrls) == 0 {
			break
		}

		goNextPageBtn, err := page.Timeout(1 * time.Second).Element(`product-review li.pagination-next:not(.disabled) a[ng-click]`)
		if err != nil {
			break
		} else {
			goNextPageBtn.MustClick().MustWaitLoad().CancelTimeout()
			time.Sleep(1 * time.Second)
		}
	}

	return hoe.Hoe{ID: id, Url: url, MainInfo: &mainInfo, DetailInfo: &detailInfo, ReportURLs: reportUrls}
}

================
File: gaito/scraper_list.go
================
package gaito

import (
	"fmt"
	"time"

	"github.com/go-rod/rod"
)

var BaseUrl = "https://www.gaito.love"

func ProcessListPage() []string {
	url := BaseUrl + "/gai-goi/khu-vuc/Hồ%20Chí%20Minh/Quận%207"
	var urlList []string

	itemThreshold := 30

	page := rod.New().Timeout(30 * time.Second).MustConnect().MustPage(url).MustWaitStable()
	defer page.Close()
	itemsQuery := `div[ng-repeat="item in products"]`

	fmt.Println("Loading...", page.MustInfo())

	for {
		items := page.MustElements(itemsQuery)
		currentLength := len(items)

		// currentLength >= itemThreshold: enough items
		// currentLength == 0: for some reason, the query doesn't return any items (Ex: Cloudflare, ...)
		if currentLength >= itemThreshold || currentLength == 0 {
			break
		}

		loadMoreBtn := page.MustElement(`body > div.container.seduction-container > div.knn_page_wrap > div.ow_page_padding > div > div > div > div > div > div:nth-child(3) > div:nth-child(4) > div > button`)
		loadMoreBtn.MustClick()

		page.MustWaitElementsMoreThan(itemsQuery, currentLength)
	}

	elements := page.MustElements(itemsQuery)
	fmt.Println("Found", len(elements), "items")
	for _, elem := range elements {
		urlList = append(urlList, *elem.MustElement(".thumbnail a").MustAttribute("href"))
	}

	return urlList
}

================
File: gaito/scraper_report.go
================
package gaito

import (
	"fmt"
	"strconv"

	"github.com/go-rod/rod"
	"github.com/haovoanh28/gai-webscraper/internal/models"
	"github.com/haovoanh28/gai-webscraper/utils"
)

func ProcessReportPage(reportUrl string) models.HoeInfo {
	url := BaseUrl + reportUrl
	id := utils.GetIDFromUrl(reportUrl)

	reportInfo := models.HoeReportInfo{
		ID:        id,
		DetailUrl: reportUrl,
	}

	page := rod.New().MustConnect().MustPage(url).MustWaitStable()
	element := page.MustElement(`review-detail-cmp`).MustWaitVisible()
	defer page.Close()

	stars, err := page.Elements(`span[ng-model="data.review.score"] i.fa-heart[ng-repeat="r in range track by $index"]`)
	if err != nil {
		panic(fmt.Errorf(`failed to get stars: %v`, err))
	}
	reportInfo.Rating = strconv.Itoa(len(stars))

	reportInfo.Description = utils.GetElementText(element, `div[ng-switch-when="textarea"] span[ng-bind="elem.question.response"]`, id+"_report_description")

	// Process author
	authorSectionElement, err := page.Element(`div.ow_page_padding > div > div > div > div > div > div:nth-child(3) > div > div.col-md-4 > div:nth-child(2) > div > div.ow_user_list_data`)
	if err != nil {
		panic(fmt.Errorf(`failed to get author section: %v`, err))
	}
	authorUrlElement := authorSectionElement.MustElement(`a.ng-binding`)
	authorUrl := authorUrlElement.MustAttribute(`href`)
	reportInfo.Author = &models.Reporter{
		ID:   utils.GetIDFromUrl(*authorUrl),
		Name: authorUrlElement.MustText(),
		Url:  *authorUrl,
	}
	reportInfo.Time = utils.GetElementText(element, `div.ow_page_padding > div > div > div > div > div > div:nth-child(3) > div > div.col-md-8 > review-detail-cmp > div:nth-child(1) > em > small`, id+"_report_time")

	return reportInfo
}

================
File: internal/models/hoe.go
================
package models

import "fmt"

type HoeInfo struct {
	ID         string   `json:"id"`
	Url        string   `json:"url"`
	Name       string   `json:"name"`
	ImageUrl   string   `json:"image_url"`
	Price      string   `json:"price"`
	Phone      string   `json:"phone"`
	Address    string   `json:"address"`
	Author     string   `json:"author"`
	Status     string   `json:"status"`
	BirthYear  string   `json:"birth_year"`
	Height     string   `json:"height"`
	Weight     string   `json:"weight"`
	From       string   `json:"from"`
	Service    string   `json:"service"`
	Duration   string   `json:"duration"`
	WorkTime   string   `json:"work_time"`
	ReportURLs []string `json:"report_urls"`
}

type HoeReportInfo struct {
	ID          string    `json:"id"`
	DetailUrl   string    `json:"detail_url"`
	Rating      string    `json:"rating"`
	Author      *Reporter `json:"author"`
	Time        string    `json:"time"`
	Description string    `json:"description"`
}

func (hoe *HoeInfo) Print() {
	fmt.Printf("=========== Hoe %s ===========\n", hoe.ID)
	fmt.Printf("Url: %s\n", hoe.Url)

	// Print all fields in Main info
	fmt.Printf("Name: %s\n", hoe.Name)
	fmt.Printf("Image url: %s\n", hoe.ImageUrl)
	fmt.Printf("Price: %s\n", hoe.Price)
	fmt.Printf("Phone: %s\n", hoe.Phone)
	fmt.Printf("Address: %s\n", hoe.Address)
	fmt.Printf("Author: %s\n", hoe.Author)
	fmt.Printf("Status: %s\n", hoe.Status)
	fmt.Printf("Birth year: %s\n", hoe.BirthYear)
	fmt.Printf("Height: %s\n", hoe.Height)
	fmt.Printf("Weight: %s\n", hoe.Weight)
	fmt.Printf("From: %s\n", hoe.From)
	fmt.Printf("Service: %s\n", hoe.Service)
	fmt.Printf("Duration: %s\n", hoe.Duration)

	fmt.Println("==============================")
	fmt.Print("\n\n")
}

================
File: internal/models/reporter.go
================
package models

type Reporter struct {
	ID   string `json:"id"`
	Name string `json:"name"`
	Url  string `json:"url"`
}

================
File: internal/sites/gaito/detail.go
================
package gaito

import (
	"fmt"
	"strings"
	"time"

	"github.com/go-rod/rod"
	"github.com/haovoanh28/gai-webscraper/internal/models"
	"github.com/haovoanh28/gai-webscraper/internal/utils"
	"github.com/haovoanh28/gai-webscraper/internal/utils/browser"
)

func ProcessDetailUrl(url string) *models.HoeInfo {
	defer func() {
		if err := recover(); err != nil {
			fmt.Printf("Error processing detail URL %s: %v\n", url, err)
		}
	}()

	result := ProcessDetailPage(url)
	return &result
}

func ProcessDetailPage(detailUrl string) models.HoeInfo {
	url := BaseUrl + detailUrl

	id := utils.GetIDFromUrl(detailUrl)

	// Wait until content element is visible
	page := rod.New().MustConnect().MustPage(url)
	containerElement := page.MustElement(`.container.seduction-container .ow_page_container`).MustWaitVisible()
	detailInfoElement := page.MustElement(`.tab-content`).MustWaitVisible()

	hoeInfo := models.HoeInfo{
		Url: url,
		ID:  id,
	}

	hoeInfo.Name = browser.GetElementsText(containerElement, `body > div.container.seduction-container > div.knn_page_wrap > div.ow_page_padding > div > div > div > div > div > div:nth-child(3) > div > h1`, "name")
	hoeInfo.ImageUrl = browser.GetElementAttribute(containerElement, `body > div.container.seduction-container > div.knn_page_wrap > div.ow_page_padding > div > div > div > div > div > div:nth-child(3) > div > div:nth-child(3) > div > div > div > div.tab-pane.ng-scope.active > div.jumbotron.ng-scope > div > div.col-md-3.col-sm-4.media.escort_item_wrap > div > image-placeholder > img`, "src", "image_url")
	// Ex: "300 k" => "300k"
	price := browser.GetElementText(detailInfoElement, `.jumbotron .fa.fa-money + span`, "price")
	hoeInfo.Price = strings.ReplaceAll(price, "\u00A0", "")
	// Ex: "0123.456.789" -> "0123456789"
	phone := browser.GetElementText(detailInfoElement, `.jumbotron .fa.fa-phone + a`, "phone")
	hoeInfo.Phone = strings.ReplaceAll(phone, ".", "")
	hoeInfo.Address = browser.GetElementText(detailInfoElement, `.jumbotron .fa.fa-map-marker + a`, "address")
	hoeInfo.Author = browser.GetElementText(detailInfoElement, `.jumbotron .fa.fa-user + a`, "author")
	hoeInfo.Status = browser.GetElementText(detailInfoElement, `.jumbotron .fa.fa-file-o + span`, "status")

	detailInfoElement = page.MustElement(`product-attribute .table-responsive`).MustWaitVisible()
	time.Sleep(2 * time.Second)
	hoeInfo.BirthYear = browser.GetElementText(detailInfoElement, `body > div.container.seduction-container > div.knn_page_wrap > div.ow_page_padding > div > div > div > div > div > div:nth-child(3) > div > div:nth-child(3) > div > div > div > div.tab-pane.ng-scope.active > div:nth-child(2) > product-attribute > div > div > div > table > tbody > tr:nth-child(3) > td:nth-child(2) > attribute-dob-box > div > div`, "birth_year")
	hoeInfo.Height = browser.GetElementText(detailInfoElement, `product-attribute table > tbody > tr:nth-child(4) > td:nth-child(2) > attribute-number-box .ng-scope`, "height") + "cm"
	hoeInfo.Weight = browser.GetElementText(detailInfoElement, `product-attribute table > tbody > tr:nth-child(5) > td:nth-child(2) > attribute-number-box .ng-scope`, "weight") + "kg"
	hoeInfo.From = browser.GetElementsText(detailInfoElement, `product-attribute table > tbody > tr:nth-child(9) > td:nth-child(2) > attribute-radio-box span span[ng-repeat="item in attributeDto.settings.values"]`, "from")
	hoeInfo.Service = browser.GetElementsText(detailInfoElement, `product-attribute table > tbody > tr:nth-child(12) > td:nth-child(2) > attribute-choices-box span span[ng-repeat="item in attributeDto.settings.values"]`, "service")
	hoeInfo.Duration = browser.GetElementText(detailInfoElement, `product-attribute table > tbody > tr:nth-child(15) > td:nth-child(2) > attribute-text-box span`, "duration")
	hoeInfo.WorkTime = browser.GetElementText(detailInfoElement, `product-attribute table > tbody > tr:nth-child(16) > td:nth-child(2) > attribute-text-box span`, "work_time")

	// Get report urls
	var reportUrls []string
	page.MustElement(`li[index="2"] a.nav-link`).MustClick().MustWaitLoad()
	time.Sleep(1 * time.Second)
	reportTabElement := page.MustElement(`product-review[ng-if="reviewTabLoaded"]`)

	for {
		reportElements, err := reportTabElement.Elements(`div[ng-repeat="review in reviews"]`)
		if err != nil {
			panic(err)
		}
		if len(reportElements) == 0 && len(reportUrls) == 0 {
			continue
			// panic(fmt.Errorf("empty reportElements ?: %v", err))
		}

		for _, reportElement := range reportElements {
			btnElement, err := reportElement.Element(`a.view_more_report`)
			if err != nil {
				panic(fmt.Errorf("failed to get view_more_report: %v", err))
			}

			reportUrl, err := btnElement.Attribute("href")
			if err != nil {
				panic(fmt.Errorf("failed to get reportUrl: %v", err))
			}
			reportUrls = append(reportUrls, *reportUrl)
		}

		if len(reportUrls) == 0 {
			break
		}

		goNextPageBtn, err := page.Timeout(1 * time.Second).Element(`product-review li.pagination-next:not(.disabled) a[ng-click]`)
		if err != nil {
			break
		} else {
			goNextPageBtn.MustClick().MustWaitLoad().CancelTimeout()
			time.Sleep(1 * time.Second)
		}
	}

	return hoeInfo
}

================
File: internal/sites/gaito/list.go
================
package gaito

import (
	"fmt"
	"time"

	"github.com/go-rod/rod"
)

func (s *Scraper) processListPage() ([]string, error) {
	const (
		itemThreshold = 30
	)

	url := s.baseURL + "/gai-goi/khu-vuc/Hồ%20Chí%20Minh/Quận%207"
	var urlList []string
	page := rod.New().Timeout(30 * time.Second).MustConnect().MustPage(url).MustWaitStable()
	defer page.Close()

	fmt.Println("Loading...", page.MustInfo())

	for {
		items := page.MustElements(listPageSelectors.Items)
		currentLength := len(items)

		// currentLength >= itemThreshold: enough items
		// currentLength == 0: for some reason, the query doesn't return any items (Ex: Cloudflare, ...)
		if currentLength >= itemThreshold || currentLength == 0 {
			break
		}

		loadMoreBtn := page.MustElement(listPageSelectors.LoadMoreBtn)
		loadMoreBtn.MustClick()

		page.MustWaitElementsMoreThan(listPageSelectors.Items, currentLength)
	}

	elements := page.MustElements(listPageSelectors.Items)
	fmt.Println("Found", len(elements), "items")
	for _, elem := range elements {
		urlList = append(urlList, *elem.MustElement(listPageSelectors.ThumbnailUrl).MustAttribute("href"))
	}

	return urlList, nil
}

================
File: internal/sites/gaito/report.go
================
package gaito

import (
	"fmt"
	"strconv"

	"github.com/go-rod/rod"
	"github.com/haovoanh28/gai-webscraper/internal/models"
	"github.com/haovoanh28/gai-webscraper/internal/utils"
	"github.com/haovoanh28/gai-webscraper/internal/utils/browser"
)

func ProcessReportPage(reportUrl string) models.HoeReportInfo {
	url := BaseUrl + reportUrl
	id := utils.GetIDFromUrl(reportUrl)

	reportInfo := models.HoeReportInfo{
		ID:        id,
		DetailUrl: reportUrl,
	}

	page := rod.New().MustConnect().MustPage(url).MustWaitStable()
	element := page.MustElement(`review-detail-cmp`).MustWaitVisible()
	defer page.Close()

	stars, err := page.Elements(`span[ng-model="data.review.score"] i.fa-heart[ng-repeat="r in range track by $index"]`)
	if err != nil {
		panic(fmt.Errorf(`failed to get stars: %v`, err))
	}
	reportInfo.Rating = strconv.Itoa(len(stars))

	reportInfo.Description = browser.GetElementText(element, `div[ng-switch-when="textarea"] span[ng-bind="elem.question.response"]`, id+"_report_description")

	// Process author
	authorSectionElement, err := page.Element(`div.ow_page_padding > div > div > div > div > div > div:nth-child(3) > div > div.col-md-4 > div:nth-child(2) > div > div.ow_user_list_data`)
	if err != nil {
		panic(fmt.Errorf(`failed to get author section: %v`, err))
	}
	authorUrlElement := authorSectionElement.MustElement(`a.ng-binding`)
	authorUrl := authorUrlElement.MustAttribute(`href`)
	reportInfo.Author = &models.Reporter{
		ID:   utils.GetIDFromUrl(*authorUrl),
		Name: authorUrlElement.MustText(),
		Url:  *authorUrl,
	}
	reportInfo.Time = browser.GetElementText(element, `div.ow_page_padding > div > div > div > div > div > div:nth-child(3) > div > div.col-md-8 > review-detail-cmp > div:nth-child(1) > em > small`, id+"_report_time")

	return reportInfo
}

================
File: internal/sites/gaito/scraper.go
================
package gaito

import "github.com/haovoanh28/gai-webscraper/internal/models"

type Scraper struct {
	baseURL        string
	requestsPerSec float64
}

func NewScraper(baseURL string, requestsPerSec float64) *Scraper {
	return &Scraper{baseURL: baseURL, requestsPerSec: requestsPerSec}
}

func (s *Scraper) GetList() []string {
	return s.processListPage()
}

func (s *Scraper) GetDetail(url string) *models.HoeInfo {
	result := ProcessDetailPage(url)
	return &result
}

================
File: internal/sites/gaito/selectors.go
================
package gaito

// ListPageSelectors contains all selectors used in list page scraping
type ListPageSelectors struct {
	Items        string
	LoadMoreBtn  string
	ThumbnailUrl string
}

var (
	listPageSelectors = ListPageSelectors{
		Items:        `div[ng-repeat="item in products"]`,
		LoadMoreBtn:  `body > div.container.seduction-container > div.knn_page_wrap > div.ow_page_padding > div > div > div > div > div > div:nth-child(3) > div:nth-child(4) > div > button`,
		ThumbnailUrl: `.thumbnail a`,
	}
)

================
File: internal/utils/browser/element.go
================
package browser

import (
	"strings"

	"github.com/go-rod/rod"
	"github.com/haovoanh28/gai-webscraper/internal/utils"
)

func GetElementWithRetry(rodElement *rod.Element, selector string, fieldName string) (*rod.Element, error) {
	return retryRodElement(func() (*rod.Element, error) {
		return rodElement.Element(selector)
	}, fieldName)
}

func GetElementText(rodElement *rod.Element, selector string, fieldName string) string {
	// element, err := rodElement.Element(selector)
	element, err := GetElementWithRetry(rodElement, selector, fieldName)
	utils.HandleError(err, "get element", fieldName)

	err = element.WaitVisible()
	utils.HandleError(err, "wait visible", fieldName)

	text, err := element.Text()
	utils.HandleError(err, "get text", fieldName)

	return strings.TrimSpace(text)
}

func GetElementAttribute(rodElement *rod.Element, selector string, attributeName string, fieldName string) string {
	element, err := GetElementWithRetry(rodElement, selector, fieldName)
	utils.HandleError(err, "get element", fieldName)

	attribute, err := element.Attribute(attributeName)
	utils.HandleError(err, "get attribute", fieldName)

	return *attribute
}

func GetElementsText(rodElement *rod.Element, selector string, fieldName string) string {
	elements, err := rodElement.Elements(selector)
	utils.HandleError(err, "get elements", fieldName)

	var texts []string
	for _, element := range elements {
		text, err := element.Text()
		utils.HandleError(err, "get text", fieldName)

		text = strings.TrimSpace(text)
		if text != "" {
			texts = append(texts, text)
		}
	}

	return strings.Join(texts, ", ")
}

================
File: internal/utils/browser/rate_limit.go
================
package browser

import "time"

type RateLimiter struct {
	interval time.Duration
	ticker   *time.Ticker
}

func NewRateLimiter(requestsPerSecond float64) *RateLimiter {
	interval := time.Duration(1000/requestsPerSecond) * time.Millisecond
	return &RateLimiter{
		interval: interval,
		ticker:   time.NewTicker(interval),
	}
}

func (r *RateLimiter) Wait() {
	<-r.ticker.C
}

================
File: internal/utils/browser/retry.go
================
package browser

import (
	"fmt"
	"time"

	"github.com/go-rod/rod"
)

func retryRodElement[T any](operation func() (T, error), fieldName string) (T, error) {
	maxAttempts := 20
	interval := 500 * time.Millisecond

	for attempt := 0; attempt < maxAttempts; attempt++ {
		result, err := operation()
		if err == nil {
			if slice, ok := any(result).([]*rod.Element); ok { // Check for multiple elements
				if len(slice) > 0 {
					return result, nil
				}
			} else if elem, ok := any(result).(*rod.Element); ok { // Check for single element
				if elem != nil {
					if visible, _ := elem.Visible(); visible {
						return result, nil
					}
				}
			}
		}
		time.Sleep(interval)
	}

	var zero T
	return zero, fmt.Errorf("failed to execute operation %s after %d attempts", fieldName, maxAttempts)
}

================
File: internal/utils/errutil/handler.go
================
package errutil

import (
	"log"
	"runtime"
	"strings"
)

type ScrapeError struct {
	Op     string // Operation being performed
	Target string // Target being scraped (URL, selector, etc)
	Err    error  // Original error
	File   string // Source file where error occurred
	Line   int    // Line number where error occurred
}

type ErrorHandler struct {
	logger   *log.Logger
	minLevel LogLevel
}

func (se *ScrapeError) Error() string {
	parts := []string{se.Op}

	if se.Target != "" {
		parts = append(parts, "target: "+se.Target)
	}
	if se.Err != nil {
		parts = append(parts, "error: "+se.Err.Error())
	}

	return strings.Join(parts, " - ")
}

func NewErrorHandler(logger *log.Logger, minLevel LogLevel) *ErrorHandler {
	if logger == nil {
		logger = log.Default()
	}

	return &ErrorHandler{logger, minLevel}
}

func (h *ErrorHandler) WrapError(op string, err error, target string) error {
	if err == nil {
		return nil
	}

	_, file, line, _ := runtime.Caller(1)

	serr := &ScrapeError{
		Op:     op,
		Target: target,
		Err:    err,
		File:   file,
		Line:   line,
	}

	h.log(ERROR, "%s at %s:%d - %v", op, file, line, err)

	return serr
}

func (h *ErrorHandler) Debug(msg string, args ...interface{}) {
	h.log(DEBUG, msg, args...)
}

func (h *ErrorHandler) Info(msg string, args ...interface{}) {
	h.log(INFO, msg, args...)
}

func (h *ErrorHandler) Warn(msg string, args ...interface{}) {
	h.log(WARN, msg, args...)
}

func (h *ErrorHandler) Error(msg string, args ...interface{}) {
	h.log(ERROR, msg, args...)
}

func (h *ErrorHandler) Fatal(msg string, args ...interface{}) {
	h.log(FATAL, msg, args...)
	panic(msg) // or os.Exit(1) depending on your needs
}

// Internal logging method
func (h *ErrorHandler) log(level LogLevel, msg string, args ...interface{}) {
	if level >= h.minLevel {
		h.logger.Printf("["+level.String()+"] "+msg, args...)
	}
}

================
File: internal/utils/errutil/level.go
================
package errutil

type LogLevel int

const (
	DEBUG LogLevel = iota
	INFO
	WARN
	ERROR
	FATAL
)

func (l LogLevel) String() string {
	switch l {
	case DEBUG:
		return "DEBUG"
	case INFO:
		return "INFO"
	case WARN:
		return "WARN"
	case ERROR:
		return "ERROR"
	case FATAL:
		return "FATAL"
	default:
		return "UNKNOWN"
	}
}

================
File: internal/utils/common.go
================
package utils

import (
	"fmt"
	"regexp"
	"strings"
)

func GetIDFromUrl(url string) string {
	url = strings.TrimSuffix(url, "/")

	// Pattern 1: "/x/y/id/z" - extract ID between segments
	re1 := regexp.MustCompile(`/([^/]+)/[^/]+$`)
	if match := re1.FindStringSubmatch(url); len(match) >= 2 {
		return match[1]
	}

	// Pattern 2: "/a/id" - extract ID at the end
	re2 := regexp.MustCompile(`/([^/]+)$`)
	if match := re2.FindStringSubmatch(url); len(match) >= 2 {
		return match[1]
	}

	return ""
}

func HandleError(err error, operation string, fieldName string) {
	if err != nil {
		panic(fmt.Errorf(`failed to %s "%s": %v`, operation, fieldName, err))
	}
}

================
File: utils/common.go
================
package utils

import (
	"fmt"
	"regexp"
	"strings"
)

func GetIDFromUrl(url string) string {
	url = strings.TrimSuffix(url, "/")

	// Pattern 1: "/x/y/id/z" - extract ID between segments
	re1 := regexp.MustCompile(`/([^/]+)/[^/]+$`)
	if match := re1.FindStringSubmatch(url); len(match) >= 2 {
		return match[1]
	}

	// Pattern 2: "/a/id" - extract ID at the end
	re2 := regexp.MustCompile(`/([^/]+)$`)
	if match := re2.FindStringSubmatch(url); len(match) >= 2 {
		return match[1]
	}

	return ""
}

func HandleError(err error, operation string, fieldName string) {
	if err != nil {
		panic(fmt.Errorf(`failed to %s "%s": %v`, operation, fieldName, err))
	}
}

================
File: utils/element.go
================
package utils

import (
	"strings"

	"github.com/go-rod/rod"
)

func GetElementWithRetry(rodElement *rod.Element, selector string, fieldName string) (*rod.Element, error) {
	return retryRodElement(func() (*rod.Element, error) {
		return rodElement.Element(selector)
	}, fieldName)
}

func GetElementText(rodElement *rod.Element, selector string, fieldName string) string {
	// element, err := rodElement.Element(selector)
	element, err := GetElementWithRetry(rodElement, selector, fieldName)
	HandleError(err, "get element", fieldName)

	err = element.WaitVisible()
	HandleError(err, "wait visible", fieldName)

	text, err := element.Text()
	HandleError(err, "get text", fieldName)

	return strings.TrimSpace(text)
}

func GetElementAttribute(rodElement *rod.Element, selector string, attributeName string, fieldName string) string {
	element, err := GetElementWithRetry(rodElement, selector, fieldName)
	HandleError(err, "get element", fieldName)

	attribute, err := element.Attribute(attributeName)
	HandleError(err, "get attribute", fieldName)

	return *attribute
}

func GetElementsText(rodElement *rod.Element, selector string, fieldName string) string {
	elements, err := rodElement.Elements(selector)
	HandleError(err, "get elements", fieldName)

	var texts []string
	for _, element := range elements {
		text, err := element.Text()
		HandleError(err, "get text", fieldName)

		text = strings.TrimSpace(text)
		if text != "" {
			texts = append(texts, text)
		}
	}

	return strings.Join(texts, ", ")
}

================
File: utils/rate_limit.go
================
package utils

import "time"

// RateLimiter provides basic rate limiting functionality
type RateLimiter struct {
	interval time.Duration
	ticker   *time.Ticker
}

func NewRateLimiter(requestsPerSecond float64) *RateLimiter {
	interval := time.Duration(1000/requestsPerSecond) * time.Millisecond
	return &RateLimiter{
		interval: interval,
		ticker:   time.NewTicker(interval),
	}
}

func (r *RateLimiter) Wait() {
	<-r.ticker.C
}

================
File: utils/retry.go
================
package utils

import (
	"fmt"
	"time"

	"github.com/go-rod/rod"
)

func retryRodElement[T any](operation func() (T, error), fieldName string) (T, error) {
	maxAttempts := 20
	interval := 500 * time.Millisecond

	for attempt := 0; attempt < maxAttempts; attempt++ {
		result, err := operation()
		if err == nil {
			if slice, ok := any(result).([]*rod.Element); ok { // Check for multiple elements
				if len(slice) > 0 {
					return result, nil
				}
			} else if elem, ok := any(result).(*rod.Element); ok { // Check for single element
				if elem != nil {
					if visible, _ := elem.Visible(); visible {
						return result, nil
					}
				}
			}
		}
		time.Sleep(interval)
	}

	var zero T
	return zero, fmt.Errorf("failed to execute operation %s after %d attempts", fieldName, maxAttempts)
}

================
File: .gitignore
================
# Binary files
*.exe
*.exe~
*.dll
*.so
*.dylib

# Binary folder (common Go build output)
/bin/

# Go specific
*.test
*.out

# IDE stuff
.idea/
.vscode/
*.swp
*.swo

# OS generated files
.DS_Store
.DS_Store?
._*

================
File: go.mod
================
module github.com/haovoanh28/gai-webscraper

go 1.23

toolchain go1.23.2

require (
	github.com/chromedp/cdproto v0.0.0-20241014181340-cb3a7a1d51d7
	github.com/chromedp/chromedp v0.11.0
)

require (
	github.com/chromedp/sysutil v1.1.0 // indirect
	github.com/go-rod/rod v0.116.2 // indirect
	github.com/gobwas/httphead v0.1.0 // indirect
	github.com/gobwas/pool v0.2.1 // indirect
	github.com/gobwas/ws v1.4.0 // indirect
	github.com/josharian/intern v1.0.0 // indirect
	github.com/mailru/easyjson v0.7.7 // indirect
	github.com/ysmood/fetchup v0.2.3 // indirect
	github.com/ysmood/goob v0.4.0 // indirect
	github.com/ysmood/got v0.40.0 // indirect
	github.com/ysmood/gson v0.7.3 // indirect
	github.com/ysmood/leakless v0.9.0 // indirect
	golang.org/x/sys v0.26.0 // indirect
)

================
File: go.sum
================
github.com/chromedp/cdproto v0.0.0-20241003230502-a4a8f7c660df/go.mod h1:GKljq0VrfU4D5yc+2qA6OVr8pmO/MBbPEWqWQ/oqGEs=
github.com/chromedp/cdproto v0.0.0-20241014181340-cb3a7a1d51d7 h1:VDBgUGgdCBw9lTKwp0KPExhnqmGfGVJQTER2MehoICk=
github.com/chromedp/cdproto v0.0.0-20241014181340-cb3a7a1d51d7/go.mod h1:GKljq0VrfU4D5yc+2qA6OVr8pmO/MBbPEWqWQ/oqGEs=
github.com/chromedp/chromedp v0.11.0 h1:1PT6O4g39sBAFjlljIHTpxmCSk8meeYL6+R+oXH4bWA=
github.com/chromedp/chromedp v0.11.0/go.mod h1:jsD7OHrX0Qmskqb5Y4fn4jHnqquqW22rkMFgKbECsqg=
github.com/chromedp/sysutil v1.0.0/go.mod h1:kgWmDdq8fTzXYcKIBqIYvRRTnYb9aNS9moAV0xufSww=
github.com/chromedp/sysutil v1.1.0 h1:PUFNv5EcprjqXZD9nJb9b/c9ibAbxiYo4exNWZyipwM=
github.com/chromedp/sysutil v1.1.0/go.mod h1:WiThHUdltqCNKGc4gaU50XgYjwjYIhKWoHGPTUfWTJ8=
github.com/go-rod/rod v0.116.2 h1:A5t2Ky2A+5eD/ZJQr1EfsQSe5rms5Xof/qj296e+ZqA=
github.com/go-rod/rod v0.116.2/go.mod h1:H+CMO9SCNc2TJ2WfrG+pKhITz57uGNYU43qYHh438Mg=
github.com/gobwas/httphead v0.1.0 h1:exrUm0f4YX0L7EBwZHuCF4GDp8aJfVeBrlLQrs6NqWU=
github.com/gobwas/httphead v0.1.0/go.mod h1:O/RXo79gxV8G+RqlR/otEwx4Q36zl9rqC5u12GKvMCM=
github.com/gobwas/pool v0.2.1 h1:xfeeEhW7pwmX8nuLVlqbzVc7udMDrwetjEv+TZIz1og=
github.com/gobwas/pool v0.2.1/go.mod h1:q8bcK0KcYlCgd9e7WYLm9LpyS+YeLd8JVDW6WezmKEw=
github.com/gobwas/ws v1.4.0 h1:CTaoG1tojrh4ucGPcoJFiAQUAsEWekEWvLy7GsVNqGs=
github.com/gobwas/ws v1.4.0/go.mod h1:G3gNqMNtPppf5XUz7O4shetPpcZ1VJ7zt18dlUeakrc=
github.com/josharian/intern v1.0.0 h1:vlS4z54oSdjm0bgjRigI+G1HpF+tI+9rE5LLzOg8HmY=
github.com/josharian/intern v1.0.0/go.mod h1:5DoeVV0s6jJacbCEi61lwdGj/aVlrQvzHFFd8Hwg//Y=
github.com/ledongthuc/pdf v0.0.0-20220302134840-0c2507a12d80 h1:6Yzfa6GP0rIo/kULo2bwGEkFvCePZ3qHDDTC3/J9Swo=
github.com/ledongthuc/pdf v0.0.0-20220302134840-0c2507a12d80/go.mod h1:imJHygn/1yfhB7XSJJKlFZKl/J+dCPAknuiaGOshXAs=
github.com/mailru/easyjson v0.7.7 h1:UGYAvKxe3sBsEDzO8ZeWOSlIQfWFlxbzLZe7hwFURr0=
github.com/mailru/easyjson v0.7.7/go.mod h1:xzfreul335JAWq5oZzymOObrkdz5UnU4kGfJJLY9Nlc=
github.com/orisano/pixelmatch v0.0.0-20220722002657-fb0b55479cde h1:x0TT0RDC7UhAVbbWWBzr41ElhJx5tXPWkIHA2HWPRuw=
github.com/orisano/pixelmatch v0.0.0-20220722002657-fb0b55479cde/go.mod h1:nZgzbfBr3hhjoZnS66nKrHmduYNpc34ny7RK4z5/HM0=
github.com/ysmood/fetchup v0.2.3 h1:ulX+SonA0Vma5zUFXtv52Kzip/xe7aj4vqT5AJwQ+ZQ=
github.com/ysmood/fetchup v0.2.3/go.mod h1:xhibcRKziSvol0H1/pj33dnKrYyI2ebIvz5cOOkYGns=
github.com/ysmood/goob v0.4.0 h1:HsxXhyLBeGzWXnqVKtmT9qM7EuVs/XOgkX7T6r1o1AQ=
github.com/ysmood/goob v0.4.0/go.mod h1:u6yx7ZhS4Exf2MwciFr6nIM8knHQIE22lFpWHnfql18=
github.com/ysmood/got v0.40.0 h1:ZQk1B55zIvS7zflRrkGfPDrPG3d7+JOza1ZkNxcc74Q=
github.com/ysmood/got v0.40.0/go.mod h1:W7DdpuX6skL3NszLmAsC5hT7JAhuLZhByVzHTq874Qg=
github.com/ysmood/gotrace v0.6.0/go.mod h1:TzhIG7nHDry5//eYZDYcTzuJLYQIkykJzCRIo4/dzQM=
github.com/ysmood/gson v0.7.3 h1:QFkWbTH8MxyUTKPkVWAENJhxqdBa4lYTQWqZCiLG6kE=
github.com/ysmood/gson v0.7.3/go.mod h1:3Kzs5zDl21g5F/BlLTNcuAGAYLKt2lV5G8D1zF3RNmg=
github.com/ysmood/leakless v0.9.0 h1:qxCG5VirSBvmi3uynXFkcnLMzkphdh3xx5FtrORwDCU=
github.com/ysmood/leakless v0.9.0/go.mod h1:R8iAXPRaG97QJwqxs74RdwzcRHT1SWCGTNqY8q0JvMQ=
golang.org/x/sys v0.6.0/go.mod h1:oPkhp1MJrh7nUepCBck5+mAzfO9JrbApNNgaTdGDITg=
golang.org/x/sys v0.26.0 h1:KHjCJyddX0LoSTb3J+vWpupP9p0oznkqVk/IfjymZbo=
golang.org/x/sys v0.26.0/go.mod h1:/VUhepiaJMQUp4+oa/7Zr1D23ma6VTLIYjOOTFZPUcA=

================
File: main.go
================
package main

import (
	"fmt"
	"sync"

	"github.com/haovoanh28/gai-webscraper/internal/models"
	"github.com/haovoanh28/gai-webscraper/internal/sites/gaito"
	"github.com/haovoanh28/gai-webscraper/internal/utils/browser"
)

func main() {
	defer func() {
		if err := recover(); err != nil {
			fmt.Println(err)
		}
	}()

	urlList := gaito.ProcessListPage()

	rateLimiter := browser.NewRateLimiter(1.0)
	urlChan := make(chan string, len(urlList))
	resultChan := make(chan models.HoeInfo, len(urlList))
	var wg sync.WaitGroup

	numWorkers := 2
	for i := 0; i < numWorkers; i++ {
		wg.Add(1)
		go func() {
			defer wg.Done()
			for url := range urlChan {
				// Wait for rate limiter before making request
				rateLimiter.Wait()

				if result := gaito.ProcessDetailUrl(url); result != nil {
					fmt.Println("Processed", url)
					resultChan <- *result
				}
			}
		}()
	}

	go func() {
		wg.Wait()
		close(resultChan)
	}()

	// Test for first 4 item
	for _, url := range urlList {
		urlChan <- url
	}
	close(urlChan)

	var hoeList []models.HoeInfo
	for hoe := range resultChan {
		hoeList = append(hoeList, hoe)
	}

	for _, hoe := range hoeList {
		hoe.Print()

		if len(hoe.ReportURLs) > 0 {
			// Process report url or put it into db ???
		}
	}

}
